{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 과제: 네이버 영화 정보 및 평점 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 대상: 예매순 상위 5개의 현재 상영 중인 영화\n",
    "- 수집할 항목: 영화 제목, 주연배우 3인, 네티즌 평점, 관람객 평점, 기자/평론가 평점, 관람객 별점 리뷰 20건 공감순으로(평점, 작성자닉네임, 리뷰본문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 예매순 상위 5개의 현재 상영 중인 영화 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "영화 제목, 주연배우 3인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_title_url_actor():\n",
    "    url = 'https://movie.naver.com/movie/running/current.nhn'\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # 1) 영화제목 긁어오기\n",
    "    tit = soup.select('dt[class=\"tit\"] a', limit = 5)\n",
    "\n",
    "    titles = []\n",
    "    for i in range(len(tit)):\n",
    "        titles.append(tit[i].get_text())\n",
    "        \n",
    "    # 2) 주연배우 긁어오기\n",
    "    actor_list = soup.select('span[class=\"link_txt\"]')\n",
    "    actors = [] # 5개영화 주연배우 모두 들어갈 리스트\n",
    "    #actor_list를 뽑았을때 주연배우가 3을 주기로 나타나기 때문에 3*i+2 수열 식을 이용하여 배우명 뽑아내기\n",
    "    for i in range(5): #영화5개에 대해\n",
    "        actor = []  #각 영화별로 주연배우 리스트\n",
    "        if len(actor_list[3*i + 2].find_all('a')) < 3: #1917예외처리를 위한 코드(주연배우가 3명이하인 경우)\n",
    "            for x in actor_list[3*i + 2].find_all('a'):\n",
    "                actor.append(x.get_text())\n",
    "            actors.append(actor)\n",
    "        else:\n",
    "            for j in range(3): #3명까지만 actor에 넣어주기\n",
    "                actor.append(actor_list[3*i + 2].find_all('a')[j].get_text())\n",
    "            actors.append(actor)\n",
    "    \n",
    "    # 3) 제목, 배우 합치기\n",
    "    #tit_act = dict(zip(titles, actors))\n",
    "    df = pd.DataFrame(index = range(0,5),columns = ['영화제목','주연배우'])\n",
    "    df['영화제목'] = titles\n",
    "    df['주연배우'] = actors\n",
    "    df['주연배우'] = df['주연배우'].str.join(',') #리스트형태로 들어오기 때문에 리스트 기호 없애주기\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 해당 영화의 평점 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네티즌 평점, 관람객 평점, 기자/평론가 평점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_grades():\n",
    "    url = 'https://movie.naver.com/movie/running/current.nhn'\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # 1) 영화 별 url 주소 뽑아내기\n",
    "    tit = soup.select('dt[class=\"tit\"] a', limit = 5)\n",
    "    tit_url = [] #리스트로 생성\n",
    "    for i in range(len(tit)):\n",
    "        tit_url.append(\"https://movie.naver.com\" + tit[i].attrs['href'])\n",
    "\n",
    "    \n",
    "    # 2) 평점 가져오기\n",
    "    data = movie_title_url_actor()\n",
    "    # df에 새로운 평점 column들 생성(어차피 밑에서 차례로 값 채울거라 일단 모든 값들 0으로 지정해둠)\n",
    "    data['관람객 평점'] = 0\n",
    "    data['기자,평론가 평점'] = 0\n",
    "    data['네티즌 평점'] = 0\n",
    "    \n",
    "    for i in range(5): #각 영화별로 접속하자\n",
    "        url = tit_url[i]\n",
    "        res = requests.get(url)\n",
    "        html = res.text\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        score = soup.select('div[class=\"star_score\"] em')\n",
    "\n",
    "        review = []\n",
    "        for j in range(8): #첫순서부터 8개 값 뽑아내면 4개씩 관람객평점, 기자평론가 평점이 나온다\n",
    "            review.append(score[j].get_text())\n",
    "\n",
    "        data['관람객 평점'][i] = review[0]+review[1]+review[2]+review[3]\n",
    "        data['기자,평론가 평점'][i] = review[4]+review[5]+review[6]+review[7]\n",
    "        data['네티즌 평점'][i] = score[-7].get_text() #네티즌평점은 저 밑에 혼자 있길래, 영화마다 위치가 동일하길래 인덱싱으로 불러옴\n",
    "        \n",
    "    return data\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 관람객 평점 공감순 20건 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평점, 평점 작성자 닉네임, 리뷰 본문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_reviews():\n",
    "    url = 'https://movie.naver.com/movie/running/current.nhn'\n",
    "    res = requests.get(url)\n",
    "    html = res.text\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    # 1) 영화제목, 영화별 url주소 긁어오기\n",
    "    tit = soup.select('dt[class=\"tit\"] a', limit = 5)\n",
    "    # 영화제목\n",
    "    titles = []\n",
    "    for t in range(len(tit)):\n",
    "        titles.append(tit[t].get_text())\n",
    "    # url 주소 뽑아내기\n",
    "    tit_url = [] #리스트로 생성\n",
    "    for i in range(len(tit)):\n",
    "        tit_url.append(\"https://movie.naver.com\" + tit[i].attrs['href'])\n",
    "        \n",
    "    #일단 tit_url에서 영화별 코드만 뽑아오자\n",
    "    news=[]\n",
    "    for j in tit_url:\n",
    "        new = re.sub('[^0-9\\s]', '', j)\n",
    "        news.append(new)\n",
    "    #영화별로 2개 페이지씩 리뷰 url 생성(한페이지당 리뷰 10개)\n",
    "    review_url = []\n",
    "    for w in news:\n",
    "        review_url.append(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + w + \"&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=1\")\n",
    "        review_url.append(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.nhn?code=\" + w + \"&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=2\")\n",
    "    \n",
    "    #새로운 데이터프레임 생성\n",
    "    df1 = pd.DataFrame(index = range(0,100),columns = ['영화제목','닉네임(아이디)','평점','리뷰'])\n",
    "    for u in range(5):\n",
    "        df1['영화제목'][20*u:20*u+20] = titles[u]\n",
    "    \n",
    "    \n",
    "    for e in range(len(review_url)):\n",
    "        url = review_url[e]\n",
    "        res = requests.get(url)\n",
    "        html = res.text\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        #닉네임(아이디)\n",
    "        names = []\n",
    "        review_name = soup.select('div[class=\"score_reple\"] a')\n",
    "        # 이렇게 a 섹션만 불러왔을때 규칙성이 있는 와중에 욕설이 섞인 리뷰는 한번 더 표시가 되기 때문에 그냥 돌리면 오류가 난다. 그래서\n",
    "        for k in range(len(review_name)): #밑에 조건문을 걸었다.\n",
    "            if review_name[k].find('span') == None: # 아이디가 들어있는 span 섹션에 혹시 아무것도 없다면\n",
    "                pass #넘어가라\n",
    "            else: #있다면 names에 추가해라\n",
    "                names.append(review_name[k].find('span').get_text())\n",
    "        df1['닉네임(아이디)'][10*e:10*e+10] = names #이 url에 해당하는 영화의 행에 차례로 다 들어가라\n",
    "        \n",
    "        #평점 #닉네임과 마찬가지\n",
    "        review_score = soup.select('div[class=\"star_score\"] em')\n",
    "        for p in range(len(review_score)):\n",
    "            review_score[p] = review_score[p].get_text()\n",
    "        df1['평점'][10*e:10*e+10] = review_score\n",
    "        \n",
    "        #리뷰\n",
    "        sooo_review_text = soup.select('div[class=\"score_reple\"] p')\n",
    "        # 리뷰는 get_text 걸어줘도 남아있는 \\n,\\t 이런 개행문자들을 전부 제거해주어야해서 함수를 만들었다\n",
    "        def space_del(text): \n",
    "            text1 = re.sub('&nbsp; | &nbsp;| \\n|\\t|\\r','',text)\n",
    "            text2 = re.sub('\\n\\n|\\n','', text1)\n",
    "            return text2\n",
    "        review_text = []\n",
    "        for m in sooo_review_text:\n",
    "            review_text.append(space_del(m.get_text()))\n",
    "        df1['리뷰'][10*e:10*e+10] = review_text\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save():\n",
    "    data = insert_grades()\n",
    "    review_data = insert_reviews()\n",
    "    \n",
    "    # csv로 저장했더니 #데이터타입 다 깨지면서 난리가 남...\n",
    "    #data.to_csv(\"naver_movie_top5.csv\")\n",
    "    #review_data.to_csv(\"naver_movie_top5_review.csv\")\n",
    "    \n",
    "    # 엑셀로 저장\n",
    "    data.to_excel(\"naver_movie_top5.xlsx\")\n",
    "    review_data.to_excel(\"naver_movie_top5_review.xlsx\")\n",
    "    \n",
    "    # pickle로 저장\n",
    "    # 피클은 파이썬의 모든 객체를 파일로 저장할 수 있는 방법으로 sklearn으로 모델학습후 저장할때 많이 사용한다\n",
    "    data.to_pickle(\"naver_movie_top5.pkl\")\n",
    "    review_data.to_pickle(\"naver_movie_top5_review.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 크롤링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "data = movie_title_url_actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영화제목</th>\n",
       "      <th>주연배우</th>\n",
       "      <th>관람객 평점</th>\n",
       "      <th>기자,평론가 평점</th>\n",
       "      <th>네티즌 평점</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>전도연,정우성,배성우</td>\n",
       "      <td>8.39</td>\n",
       "      <td>6.71</td>\n",
       "      <td>6.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>정직한 후보</td>\n",
       "      <td>라미란,김무열,나문희</td>\n",
       "      <td>8.61</td>\n",
       "      <td>5.38</td>\n",
       "      <td>7.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917</td>\n",
       "      <td>조지 맥케이,딘-찰스 채프먼</td>\n",
       "      <td>9.43</td>\n",
       "      <td>7.67</td>\n",
       "      <td>8.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>작은 아씨들</td>\n",
       "      <td>시얼샤 로넌,엠마 왓슨,플로렌스 퓨</td>\n",
       "      <td>9.21</td>\n",
       "      <td>8.00</td>\n",
       "      <td>8.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>하정우,김남길,허율</td>\n",
       "      <td>8.39</td>\n",
       "      <td>5.50</td>\n",
       "      <td>6.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               영화제목                 주연배우 관람객 평점 기자,평론가 평점 네티즌 평점\n",
       "0  지푸라기라도 잡고 싶은 짐승들          전도연,정우성,배성우   8.39      6.71   6.88\n",
       "1            정직한 후보          라미란,김무열,나문희   8.61      5.38   7.71\n",
       "2              1917      조지 맥케이,딘-찰스 채프먼   9.43      7.67   8.99\n",
       "3            작은 아씨들  시얼샤 로넌,엠마 왓슨,플로렌스 퓨   9.21      8.00   8.88\n",
       "4               클로젯           하정우,김남길,허율   8.39      5.50   6.86"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = insert_grades()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>영화제목</th>\n",
       "      <th>닉네임(아이디)</th>\n",
       "      <th>평점</th>\n",
       "      <th>리뷰</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>어쩌라고(dpfk****)</td>\n",
       "      <td>1</td>\n",
       "      <td>아니 개봉당일날 9시 땡하고 부터 평점 쏟아지는게 말이 돼냐? 요즘 조조는 꼭두새벽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>bohemian(mabu****)</td>\n",
       "      <td>10</td>\n",
       "      <td>난 전도연의 화류계 캐릭터가 좋다. 무뢰한, 너는 내 운명, 카운트다운...그리고 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>최정규(cjg4****)</td>\n",
       "      <td>10</td>\n",
       "      <td>전도연 연기 진짜 오진다...와 이 영화에서 완전 섹시하게 나온다 역시 명불허전임...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>달다(fxko****)</td>\n",
       "      <td>10</td>\n",
       "      <td>8명의 배우가 모두 주인공 같은 느낌.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>지푸라기라도 잡고 싶은 짐승들</td>\n",
       "      <td>써니(tlag****)</td>\n",
       "      <td>9</td>\n",
       "      <td>개존잼 역시 전도연이죠? 카리스마 미쳐벌여ㅠㅁㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>지애(maln****)</td>\n",
       "      <td>1</td>\n",
       "      <td>관람객최근에 본 것 중에 제일 최악..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>삡(jiny****)</td>\n",
       "      <td>10</td>\n",
       "      <td>김남길 눈빛이 다했다..재밌어요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>maimai(enma****)</td>\n",
       "      <td>10</td>\n",
       "      <td>진짜 심장 쫄깃하고 무서움 ㄷㄷㄷ 이건 극장에서 봐야함</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>난꽃이다(play****)</td>\n",
       "      <td>10</td>\n",
       "      <td>무서운거 진짜 못보는대 혼자 봤거든요 걱정하시는분들 그걸 감안하고라도 보시는거 추천...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>클로젯</td>\n",
       "      <td>곰수니(goms****)</td>\n",
       "      <td>10</td>\n",
       "      <td>관람객하정우 김남길 케미 생각보다 좋고 생각보다 무서웠음 ㄷㄷㄷ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                영화제목            닉네임(아이디)  평점  \\\n",
       "0   지푸라기라도 잡고 싶은 짐승들      어쩌라고(dpfk****)   1   \n",
       "1   지푸라기라도 잡고 싶은 짐승들  bohemian(mabu****)  10   \n",
       "2   지푸라기라도 잡고 싶은 짐승들       최정규(cjg4****)  10   \n",
       "3   지푸라기라도 잡고 싶은 짐승들        달다(fxko****)  10   \n",
       "4   지푸라기라도 잡고 싶은 짐승들        써니(tlag****)   9   \n",
       "..               ...                 ...  ..   \n",
       "95               클로젯        지애(maln****)   1   \n",
       "96               클로젯         삡(jiny****)  10   \n",
       "97               클로젯    maimai(enma****)  10   \n",
       "98               클로젯      난꽃이다(play****)  10   \n",
       "99               클로젯       곰수니(goms****)  10   \n",
       "\n",
       "                                                   리뷰  \n",
       "0   아니 개봉당일날 9시 땡하고 부터 평점 쏟아지는게 말이 돼냐? 요즘 조조는 꼭두새벽...  \n",
       "1   난 전도연의 화류계 캐릭터가 좋다. 무뢰한, 너는 내 운명, 카운트다운...그리고 ...  \n",
       "2   전도연 연기 진짜 오진다...와 이 영화에서 완전 섹시하게 나온다 역시 명불허전임...   \n",
       "3                              8명의 배우가 모두 주인공 같은 느낌.   \n",
       "4                         개존잼 역시 전도연이죠? 카리스마 미쳐벌여ㅠㅁㅠ   \n",
       "..                                                ...  \n",
       "95                             관람객최근에 본 것 중에 제일 최악..   \n",
       "96                                 김남길 눈빛이 다했다..재밌어요   \n",
       "97                    진짜 심장 쫄깃하고 무서움 ㄷㄷㄷ 이건 극장에서 봐야함   \n",
       "98  무서운거 진짜 못보는대 혼자 봤거든요 걱정하시는분들 그걸 감안하고라도 보시는거 추천...  \n",
       "99               관람객하정우 김남길 케미 생각보다 좋고 생각보다 무서웠음 ㄷㄷㄷ   \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#영화리뷰는 따로 저장\n",
    "review_data = insert_reviews()\n",
    "review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "영화제목        0\n",
       "닉네임(아이디)    0\n",
       "평점          0\n",
       "리뷰          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결측치 있나 저장하기 전에 한번 확인해보자\n",
    "review_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치 없이 아주 잘 채워졌다......!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#저장합시다~\n",
    "save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
